{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Vincent\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# @title Imports (run this cell)\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Add some convenience functions to Pandas DataFrame.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "def mask(df, key, function):\n",
    "  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n",
    "  return df[function(df[key])]\n",
    "\n",
    "def flatten_cols(df):\n",
    "  df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "  return df\n",
    "\n",
    "pd.DataFrame.mask = mask\n",
    "pd.DataFrame.flatten_cols = flatten_cols\n",
    "\n",
    "# Install Altair and activate its colab renderer.\n",
    "# print(\"Installing Altair...\")\n",
    "# !pip install git+git://github.com/altair-viz/altair.git\n",
    "# import altair as alt\n",
    "# alt.data_transformers.enable('default', max_rows=None)\n",
    "# alt.renderers.enable('colab')\n",
    "# print(\"Done installing Altair.\")\n",
    "\n",
    "# Install spreadsheets and import authentication module.\n",
    "USER_RATINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each data set (users, movies, and ratings).\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('../datasets/movielens_original/ratings-1M.csv')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv('../datasets/movielens_original/movies-1M.csv')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "# users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x-1))\n",
    "movies[\"movieId\"] = movies[\"movieId\"].apply(lambda x: str(x-1))\n",
    "# movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "ratings[\"movieId\"] = ratings[\"movieId\"].apply(lambda x: str(x-1))\n",
    "ratings[\"userId\"] = ratings[\"userId\"].apply(lambda x: str(x-1))\n",
    "# ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))\n",
    "\n",
    "# Compute the number of movies to which a genre is assigned.\n",
    "# genre_occurences = movies[genre_cols].sum().to_dict()\n",
    "\n",
    "# Since some movies can belong to more than one genre, we create different\n",
    "# 'genre' columns as follows:\n",
    "# - all_genres: all the active genres of the movie.\n",
    "# - genre: randomly sampled from the active genres.\n",
    "# def mark_genres(movies, genres):\n",
    "#   def get_random_genre(gs):\n",
    "#     active = [genre for genre, g in zip(genres, gs) if g==1]\n",
    "#     if len(active) == 0:\n",
    "#       return 'Other'\n",
    "#     return np.random.choice(active)\n",
    "#   def get_all_genres(gs):\n",
    "#     active = [genre for genre, g in zip(genres, gs) if g==1]\n",
    "#     if len(active) == 0:\n",
    "#       return 'Other'\n",
    "#     return '-'.join(active)\n",
    "#   movies['genre'] = [\n",
    "#       get_random_genre(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "#   movies['all_genres'] = [\n",
    "#       get_all_genres(gs) for gs in zip(*[movies[genre] for genre in genres])]\n",
    "\n",
    "# mark_genres(movies, genre_cols)\n",
    "\n",
    "# Create one merged DataFrame containing all the movielens data.\n",
    "movielens = ratings.merge(movies, on='movieId')\n",
    "\n",
    "# Utility to split the data into training and test sets.\n",
    "def split_dataframe(df, holdout_fraction=0.1):\n",
    "  test = df.sample(frac=holdout_fraction, replace=False)\n",
    "  train = df[~df.index.isin(test.index)]\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rating_sparse_tensor(ratings_df):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    ratings_df: a pd.DataFrame with `user_id`, `movie_id` and `rating` columns.\n",
    "  Returns:\n",
    "    a tf.SparseTensor representing the ratings matrix.\n",
    "  \"\"\"\n",
    "  indices = ratings_df[['user_id', 'movie_id']].values\n",
    "  values = ratings_df['rating'].values\n",
    "  return tf.SparseTensor(\n",
    "      indices=indices,\n",
    "      values=values,\n",
    "      dense_shape=[ratings.userId.nunique(), movies.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mean_square_error(sparse_ratings, user_embeddings, movie_embeddings):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    sparse_ratings: A SparseTensor rating matrix, of dense_shape [N, M]\n",
    "    user_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
    "      dimension, such that U_i is the embedding of user i.\n",
    "    movie_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
    "      dimension, such that V_j is the embedding of movie j.\n",
    "  Returns:\n",
    "    A scalar Tensor representing the MSE between the true ratings and the\n",
    "      model's predictions.\n",
    "  \"\"\"\n",
    "  predictions = tf.gather_nd(\n",
    "      tf.matmul(user_embeddings, movie_embeddings, transpose_b=True),\n",
    "      sparse_ratings.indices)\n",
    "  loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_RATINGS = True #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run to load your ratings.\n",
    "# Load the ratings from the spreadsheet and create a DataFrame.\n",
    "if USER_RATINGS:\n",
    "  my_ratings = pd.DataFrame.from_records(worksheet.get_all_values()).reset_index()\n",
    "  my_ratings = my_ratings[my_ratings[1] != '']\n",
    "  my_ratings = pd.DataFrame({\n",
    "      'user_id': \"943\",\n",
    "      'movie_id': list(map(str, my_ratings['index'])),\n",
    "      'rating': list(map(float, my_ratings[1])),\n",
    "  })\n",
    "  # Remove previous ratings.\n",
    "  ratings = ratings[ratings.user_id != \"943\"]\n",
    "  # Add new ratings.\n",
    "  ratings = ratings.append(my_ratings, ignore_index=True)\n",
    "  # Add new user to the users DataFrame.\n",
    "  if users.shape[0] == 943:\n",
    "    users = users.append(users.iloc[942], ignore_index=True)\n",
    "    users[\"user_id\"][943] = \"943\"\n",
    "  print(\"Added your %d ratings; you have great taste!\" % len(my_ratings))\n",
    "  ratings[ratings.user_id==\"943\"].merge(movies[['movie_id', 'title']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
